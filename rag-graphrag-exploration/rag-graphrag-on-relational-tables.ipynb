{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb743f8",
   "metadata": {},
   "source": [
    "# RAG & GraphRAG over a Relational Schema\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. A simple **relational RAG** pattern:\n",
    "   - Filter with \"SQL\" (simulated using pandas DataFrames)\n",
    "   - Create textual summaries per row\n",
    "   - Embed and retrieve relevant rows for a user question\n",
    "\n",
    "2. A **GraphRAG-style approach**:\n",
    "   - Build a small knowledge graph on top of the same schema\n",
    "   - Use graph traversal to find a relevant neighborhood\n",
    "   - Run RAG *on that neighborhood* for more relational / multi-hop questions\n",
    "\n",
    "In a real enterprise setting, you would:\n",
    "- Replace the pandas DataFrames with your actual warehouse / OLTP DB\n",
    "- Replace the fake embeddings with a real embedding model (OpenAI, Snowflake Cortex, etc.)\n",
    "- Replace the in-memory NetworkX graph with a GraphDB (Neo4j, Neptune, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5461dd12",
   "metadata": {},
   "source": [
    "## 1. Mock Relational Schema\n",
    "\n",
    "We'll simulate a simple schema with three tables:\n",
    "\n",
    "- `customers`: basic customer profile\n",
    "- `orders`: orders placed by customers\n",
    "- `tickets`: support tickets raised by customers\n",
    "\n",
    "Assume that, in production, each of these tables has **millions of rows**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab04f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# For the GraphRAG part\n",
    "import networkx as nx\n",
    "\n",
    "# Set a fixed random seed for reproducibility (only affects fake embeddings)\n",
    "RNG = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8176649",
   "metadata": {},
   "source": [
    "### Create Mock Tables\n",
    "\n",
    "We'll create a few example rows. In a real system, this schema would be populated\n",
    "with millions of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ca980a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   customer_id        name     segment region\n",
       " 0            1   Acme Corp  Enterprise     NA\n",
       " 1            2  Globex Inc  Mid-Market     EU\n",
       " 2            3     Initech         SMB     NA,\n",
       "    order_id  customer_id              product  amount   status\n",
       " 0       101            1  Observability Suite  250000   Active\n",
       " 1       102            1  Incident Automation   90000  Churned\n",
       " 2       103            2  Observability Suite   60000   Active\n",
       " 3       104            3        Log Analytics   15000    Trial,\n",
       "    ticket_id  customer_id severity              topic  status\n",
       " 0       1001            1       P1   Frequent outages    Open\n",
       " 1       1002            1       P2    Slow dashboards  Closed\n",
       " 2       1003            2       P3  Billing questions    Open\n",
       " 3       1004            3       P1    Agent CPU usage  Closed,\n",
       "    ticket_id  customer_id severity              topic  status\n",
       " 0       1001            1       P1   Frequent outages    Open\n",
       " 1       1002            1       P2    Slow dashboards  Closed\n",
       " 2       1003            2       P3  Billing questions    Open\n",
       " 3       1004            3       P1    Agent CPU usage  Closed)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers = pd.DataFrame(\n",
    "    [\n",
    "        {\"customer_id\": 1, \"name\": \"Acme Corp\", \"segment\": \"Enterprise\", \"region\": \"NA\"},\n",
    "        {\"customer_id\": 2, \"name\": \"Globex Inc\", \"segment\": \"Mid-Market\", \"region\": \"EU\"},\n",
    "        {\"customer_id\": 3, \"name\": \"Initech\", \"segment\": \"SMB\", \"region\": \"NA\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "orders = pd.DataFrame(\n",
    "    [\n",
    "        {\"order_id\": 101, \"customer_id\": 1, \"product\": \"Observability Suite\", \"amount\": 250000, \"status\": \"Active\"},\n",
    "        {\"order_id\": 102, \"customer_id\": 1, \"product\": \"Incident Automation\", \"amount\": 90000, \"status\": \"Churned\"},\n",
    "        {\"order_id\": 103, \"customer_id\": 2, \"product\": \"Observability Suite\", \"amount\": 60000, \"status\": \"Active\"},\n",
    "        {\"order_id\": 104, \"customer_id\": 3, \"product\": \"Log Analytics\", \"amount\": 15000, \"status\": \"Trial\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "tickets = pd.DataFrame(\n",
    "    [\n",
    "        {\"ticket_id\": 1001, \"customer_id\": 1, \"severity\": \"P1\", \"topic\": \"Frequent outages\", \"status\": \"Open\"},\n",
    "        {\"ticket_id\": 1002, \"customer_id\": 1, \"severity\": \"P2\", \"topic\": \"Slow dashboards\", \"status\": \"Closed\"},\n",
    "        {\"ticket_id\": 1003, \"customer_id\": 2, \"severity\": \"P3\", \"topic\": \"Billing questions\", \"status\": \"Open\"},\n",
    "        {\"ticket_id\": 1004, \"customer_id\": 3, \"severity\": \"P1\", \"topic\": \"Agent CPU usage\", \"status\": \"Closed\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "customers, orders, tickets.head(), tickets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97f8dde",
   "metadata": {},
   "source": [
    "In production, these tables would live in a database like Postgres, Snowflake, BigQuery, etc.\n",
    "The schema would be the same; only the **row counts** would be much larger.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f54ec08",
   "metadata": {},
   "source": [
    "## 2. Classic Relational RAG Pattern\n",
    "\n",
    "### 2.1. Textual \"Row Summaries\" for RAG\n",
    "\n",
    "We want to answer questions like:\n",
    "\n",
    "> \"Why is Acme Corp at risk of churn?\"\n",
    "\n",
    "We'll:\n",
    "- Join data from multiple tables\n",
    "- Create concise textual summaries\n",
    "- Embed those summaries\n",
    "- Retrieve top-k summaries given a user question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da4e62a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Acme Corp</td>\n",
       "      <td>Customer Acme Corp (segment: Enterprise, regio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Globex Inc</td>\n",
       "      <td>Customer Globex Inc (segment: Mid-Market, regi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Initech</td>\n",
       "      <td>Customer Initech (segment: SMB, region: NA). T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id        name                                            summary\n",
       "0            1   Acme Corp  Customer Acme Corp (segment: Enterprise, regio...\n",
       "1            2  Globex Inc  Customer Globex Inc (segment: Mid-Market, regi...\n",
       "2            3     Initech  Customer Initech (segment: SMB, region: NA). T..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_customer_context_rows(\n",
    "    customers: pd.DataFrame, orders: pd.DataFrame, tickets: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build an aggregated, textual view per customer to use as the RAG 'document'.\n",
    "    \"\"\"\n",
    "    # Aggregate orders\n",
    "    order_agg = (\n",
    "        orders.groupby(\"customer_id\")\n",
    "        .agg(\n",
    "            total_revenue=(\"amount\", \"sum\"),\n",
    "            products=(\"product\", lambda x: list(sorted(set(x)))),\n",
    "            churned_products=(\"status\", lambda x: list(sorted(set([s for s in x if s == \"Churned\"])))),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Aggregate tickets\n",
    "    ticket_agg = (\n",
    "        tickets.groupby(\"customer_id\")\n",
    "        .agg(\n",
    "            open_p1=(\"severity\", lambda x: sum((s == \"P1\") for s in x)),\n",
    "            open_tickets=(\"status\", lambda x: sum((s == \"Open\") for s in x)),\n",
    "            topics=(\"topic\", lambda x: list(x)),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    df = customers.merge(order_agg, on=\"customer_id\", how=\"left\").merge(ticket_agg, on=\"customer_id\", how=\"left\")\n",
    "\n",
    "    # First: fill scalar numeric values safely\n",
    "    df = df.fillna({\n",
    "        \"total_revenue\": 0,\n",
    "        \"open_p1\": 0,\n",
    "        \"open_tickets\": 0,\n",
    "    })\n",
    "\n",
    "    # Second: fill list columns using apply (because fillna doesn't accept lists)\n",
    "    for list_col in [\"products\", \"churned_products\", \"topics\"]:\n",
    "        df[list_col] = df[list_col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "        \n",
    "    def make_summary(row):\n",
    "        return (\n",
    "            f\"Customer {row['name']} (segment: {row['segment']}, region: {row['region']}). \"\n",
    "            f\"Total revenue: {row['total_revenue']}. \"\n",
    "            f\"Products: {', '.join(row['products']) or 'None'}. \"\n",
    "            f\"Churned products: {', '.join(row['churned_products']) or 'None'}. \"\n",
    "            f\"Open P1 tickets: {row['open_p1']}. \"\n",
    "            f\"Open tickets: {row['open_tickets']}. \"\n",
    "            f\"Recent ticket topics: {', '.join(row['topics']) or 'None'}.\"\n",
    "        )\n",
    "\n",
    "    df[\"summary\"] = df.apply(make_summary, axis=1)\n",
    "    return df[[\"customer_id\", \"name\", \"summary\"]]\n",
    "\n",
    "\n",
    "customer_context = build_customer_context_rows(customers, orders, tickets)\n",
    "customer_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e96df1",
   "metadata": {},
   "source": [
    "## 2. Classic Relational RAG Pattern\n",
    "\n",
    "### 2.1. Textual \"Row Summaries\" for RAG\n",
    "\n",
    "We want to answer questions like:\n",
    "\n",
    "> \"Why is Acme Corp at risk of churn?\"\n",
    "\n",
    "We'll:\n",
    "- Join data from multiple tables\n",
    "- Create concise textual summaries\n",
    "- Embed those summaries\n",
    "- Retrieve top-k summaries given a user question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2da180",
   "metadata": {},
   "source": [
    "### 2.2. Fake Embeddings (Replace with Real Model in Production)\n",
    "\n",
    "We use deterministic pseudo-random vectors as stand-ins for real embeddings so the notebook runs offline.\n",
    "\n",
    "In a real system, you would do something like:\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def embed_text(text: str) -> np.ndarray:\n",
    "    resp = client.embeddings.create(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        input=[text]\n",
    "    )\n",
    "    return np.array(resp.data[0].embedding)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e99fc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBED_DIM = 64 # small dim for the example\n",
    "\n",
    "def fake_embed_text(text: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Deterministic 'fake' embedding based on text hash.\n",
    "    \"\"\"\n",
    "    seed = abs(hash(text)) % (2**32)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return rng.normal(size=(EMBED_DIM,))\n",
    "\n",
    "def embed_corpus(df: pd.DataFrame, text_col: str = \"summary\") -> np.ndarray:\n",
    "    vectors = np.vstack([fake_embed_text(t) for t in df[text_col].tolist()])\n",
    "    return vectors\n",
    "\n",
    "customer_vectors = embed_corpus(customer_context, \"summary\")\n",
    "customer_vectors.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab923ee0",
   "metadata": {},
   "source": [
    "### 2.3. Simple Vector Retrieval\n",
    "We'll:\n",
    "\n",
    "Embed the user query\n",
    "\n",
    "Compute cosine similarity vs. all customer summaries\n",
    "\n",
    "Return the top-k customers as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feb30f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Acme Corp</td>\n",
       "      <td>Customer Acme Corp (segment: Enterprise, regio...</td>\n",
       "      <td>0.239732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Globex Inc</td>\n",
       "      <td>Customer Globex Inc (segment: Mid-Market, regi...</td>\n",
       "      <td>0.075303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Initech</td>\n",
       "      <td>Customer Initech (segment: SMB, region: NA). T...</td>\n",
       "      <td>-0.128087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id        name                                            summary  \\\n",
       "0            1   Acme Corp  Customer Acme Corp (segment: Enterprise, regio...   \n",
       "1            2  Globex Inc  Customer Globex Inc (segment: Mid-Market, regi...   \n",
       "2            3     Initech  Customer Initech (segment: SMB, region: NA). T...   \n",
       "\n",
       "      score  \n",
       "0  0.239732  \n",
       "1  0.075303  \n",
       "2 -0.128087  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-9))\n",
    "\n",
    "def retrieve_customers(question: str, top_k: int = 2):\n",
    "    q_vec = fake_embed_text(question)\n",
    "    sims = [cosine_sim(q_vec, v) for v in customer_vectors]\n",
    "    indices = np.argsort(sims)[::-1][:top_k]\n",
    "    return customer_context.iloc[indices].assign(score=[sims[i] for i in indices])\n",
    "\n",
    "example_question = \"Why is Acme Corp at risk of churn, and what issues are they facing?\"\n",
    "retrieve_customers(example_question, top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6442d0",
   "metadata": {},
   "source": [
    "### 2.4. Agentic Answer Stub\n",
    "In a real system, an agent (LLM) would:\n",
    "\n",
    "Decide which tool to use (relational_rag, graph_rag, docs_rag, etc.)\n",
    "\n",
    "Call the retriever\n",
    "\n",
    "Use the results as context in a final generation step\n",
    "\n",
    "Below is a simplified version that just concatenates retrieved context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c087bd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: Why is Acme Corp at risk of churn, and what issues are they facing?\n",
      "\n",
      "CONTEXT (top 2 customers):\n",
      "[Customer Acme Corp]\n",
      "Customer Acme Corp (segment: Enterprise, region: NA). Total revenue: 340000. Products: Incident Automation, Observability Suite. Churned products: Churned. Open P1 tickets: 1. Open tickets: 1. Recent ticket topics: Frequent outages, Slow dashboards.\n",
      "\n",
      "[Customer Globex Inc]\n",
      "Customer Globex Inc (segment: Mid-Market, region: EU). Total revenue: 60000. Products: Observability Suite. Churned products: None. Open P1 tickets: 0. Open tickets: 1. Recent ticket topics: Billing questions.\n",
      "\n",
      "LLM_ANSWER (pseudo): Based on the context above, here is how I would explain the situation...\n"
     ]
    }
   ],
   "source": [
    "def answer_with_relational_rag(question: str, top_k: int = 2) -> str:\n",
    "    retrieved = retrieve_customers(question, top_k=top_k)\n",
    "    context_blocks = []\n",
    "    for _, row in retrieved.iterrows():\n",
    "        context_blocks.append(f\"[Customer {row['name']}]\\n{row['summary']}\\n\")\n",
    "        context = \"\\n\".join(context_blocks)\n",
    "\n",
    "    # In production: call LLM with this context\n",
    "    # Here we just echo a template.\n",
    "    \n",
    "    answer = (\n",
    "        f\"QUESTION: {question}\\n\\n\"\n",
    "        f\"CONTEXT (top {top_k} customers):\\n{context}\\n\"\n",
    "        \"LLM_ANSWER (pseudo): Based on the context above, here is how I would explain the situation...\"\n",
    "    )\n",
    "    return answer\n",
    "\n",
    "print(answer_with_relational_rag(example_question, top_k=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d040af",
   "metadata": {},
   "source": [
    "This demonstrates a classic relational RAG pattern:\n",
    "- Coarse-grain selection via query (or time filters, segment, region, etc.)\n",
    "- Vector similarity over textual summaries\n",
    "- Context passed to an LLM for answer synthesis\n",
    "\n",
    "In a real deployment:\n",
    "- Step 1 might be actual SQL, not DataFrame filtering\n",
    "- Step 2 might use a proper vector DB (pgvector, Pinecone, etc.)\n",
    "= Step 3 uses an LLM API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce7db13",
   "metadata": {},
   "source": [
    "### 3. Building a Simple Knowledge Graph\n",
    "Now let's layer a graph on top of the same data. We'll create a graph with:\n",
    "= Node types: Customer, Order, Ticket\n",
    "= Edges:\n",
    "    - Customer → Order (PLACED)\n",
    "    - Customer → Ticket (RAISED)\n",
    "    - Optionally, Order → Ticket or service dependencies, etc.\n",
    "\n",
    "This simulates what you'd store in a GraphDB (Neo4j, Neptune, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7451d3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.MultiDiGraph()\n",
    "\n",
    "# Add customer nodes\n",
    "for _, row in customers.iterrows():\n",
    "    G.add_node(\n",
    "    f\"customer:{row['customer_id']}\",\n",
    "    label=\"Customer\",\n",
    "    customer_id=row[\"customer_id\"],\n",
    "    name=row[\"name\"],\n",
    "    segment=row[\"segment\"],\n",
    "    region=row[\"region\"],\n",
    "    )\n",
    "\n",
    "# Add order nodes and edges\n",
    "for _, row in orders.iterrows():\n",
    "    node_id = f\"order:{row['order_id']}\"\n",
    "    G.add_node(\n",
    "        node_id,\n",
    "        label=\"Order\",\n",
    "        order_id=row[\"order_id\"],\n",
    "        customer_id=row[\"customer_id\"],\n",
    "        product=row[\"product\"],\n",
    "        amount=row[\"amount\"],\n",
    "        status=row[\"status\"],\n",
    "    )\n",
    "    G.add_edge(f\"customer:{row['customer_id']}\", node_id, relation=\"PLACED\")\n",
    "\n",
    "# Add ticket nodes and edges\n",
    "for _, row in tickets.iterrows():\n",
    "    node_id = f\"ticket:{row['ticket_id']}\"\n",
    "    G.add_node(\n",
    "        node_id,\n",
    "        label=\"Ticket\",\n",
    "        ticket_id=row[\"ticket_id\"],\n",
    "        customer_id=row[\"customer_id\"],\n",
    "        severity=row[\"severity\"],\n",
    "        topic=row[\"topic\"],\n",
    "        status=row[\"status\"],\n",
    "    )\n",
    "    G.add_edge(f\"customer:{row['customer_id']}\", node_id, relation=\"RAISED\")\n",
    "\n",
    "len(G.nodes()), len(G.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2838dc",
   "metadata": {},
   "source": [
    "### 3.1. Graph-Based Node Descriptions\n",
    "We now define textual descriptions for nodes. In a real GraphRAG system, these might be:\n",
    "- Long-form descriptions of entities\n",
    "- Enriched with logs, comments, documentation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5991497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def describe_node(node_id: str, attrs: Dict[str, Any]) -> str:\n",
    "    label = attrs.get(\"label\")\n",
    "    if label == \"Customer\":\n",
    "        return (\n",
    "            f\"Customer {attrs['name']} (segment: {attrs['segment']}, region: {attrs['region']}). \"\n",
    "            f\"Node: {node_id}.\"\n",
    "        )\n",
    "    elif label == \"Order\":\n",
    "        return (\n",
    "            f\"Order {attrs['order_id']} for customer {attrs['customer_id']}. \"\n",
    "            f\"Product: {attrs['product']}, amount: {attrs['amount']}, status: {attrs['status']}. \"\n",
    "            f\"Node: {node_id}.\"\n",
    "        )\n",
    "    elif label == \"Ticket\":\n",
    "        return (\n",
    "            f\"Ticket {attrs['ticket_id']} for customer {attrs['customer_id']}. \"\n",
    "            f\"Severity: {attrs['severity']}, topic: {attrs['topic']}, status: {attrs['status']}. \"\n",
    "            f\"Node: {node_id}.\"\n",
    "        )\n",
    "    else:\n",
    "        return f\"Node {node_id} with attributes {attrs}\"\n",
    "\n",
    "# Precompute descriptions & embeddings\n",
    "node_descriptions = {}\n",
    "node_vectors = {}\n",
    "\n",
    "for node_id, attrs in G.nodes(data=True):\n",
    "    desc = describe_node(node_id, attrs)\n",
    "    node_descriptions[node_id] = desc\n",
    "    node_vectors[node_id] = fake_embed_text(desc)\n",
    "\n",
    "len(node_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fdc1eb",
   "metadata": {},
   "source": [
    "### 3.2. GraphRAG Retrieval\n",
    "A rough GraphRAG pattern: \n",
    "- Embed user question\n",
    "- Compute similarity to node descriptions (e.g. Customers, Tickets)\n",
    "- Take the top-N nodes as entry points\n",
    "- Traverse the graph to collect a small neighborhood (e.g. radius 1–2)\n",
    "- Build context from the neighborhood (customers + tickets + orders)\n",
    "- Feed that into the LLM\n",
    "\n",
    "This lets you answer relational / multi-hop questions more naturally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "820f28dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[customer:1] Customer Acme Corp (segment: Enterprise, region: NA). Node: customer:1.\\n[customer:3] Customer Initech (segment: SMB, region: NA). Node: customer:3.\\n[order:101] Order 101 for customer 1. Product: Observability Suite, amount: 250000, status: Active. Node: order:101.\\n[order:102] Order 102 for customer 1. Product: Incident Automation, amount: 90000, status: Churned. Node: order:102.\\n[order:104] Order 104 for customer 3. Product: Log Analytics, amount: 15000, status: Trial. Node: order:104.\\n[ticket:1001] Ticket 1001 for customer 1. Severity: P1, topic: Frequent outages, status: Open. Node: ticket:1001.\\n[ticket:1002] Ticket 1002 for customer 1. Severity: P2, topic: Slow dashboards, status: Closed. Node: ticket:1002.\\n[ticket:1004] Ticket 1004 for customer 3. Severity: P1, topic: Agent CPU usage, status: Closed. Node: ticket:1004.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_graph_neighborhood(question: str, top_n_nodes: int = 3, max_hops: int = 2):\n",
    "    q_vec = fake_embed_text(question)\n",
    "\n",
    "    # Rank nodes by similarity to the question\n",
    "    scores = []\n",
    "    for node_id, vec in node_vectors.items():\n",
    "        scores.append((node_id, cosine_sim(q_vec, vec)))\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    seed_nodes = [node_id for node_id, _ in scores[:top_n_nodes]]\n",
    "\n",
    "    # BFS up to max_hops for each seed node\n",
    "    neighborhood = set()\n",
    "    for seed in seed_nodes:\n",
    "        neighborhood.add(seed)\n",
    "        # simple BFS\n",
    "        queue = [(seed, 0)]\n",
    "        while queue:\n",
    "            current, depth = queue.pop(0)\n",
    "            if depth >= max_hops:\n",
    "                continue\n",
    "            # neighbors in both directions\n",
    "            neighbors = list(G.predecessors(current)) + list(G.successors(current))\n",
    "            for nb in neighbors:\n",
    "                if nb not in neighborhood:\n",
    "                    neighborhood.add(nb)\n",
    "                    queue.append((nb, depth + 1))\n",
    "\n",
    "    # Build context text\n",
    "    context_nodes = sorted(list(neighborhood))\n",
    "    context_texts = [f\"[{nid}] {node_descriptions[nid]}\" for nid in context_nodes]\n",
    "\n",
    "    return {\n",
    "        \"seed_nodes\": seed_nodes,\n",
    "        \"neighborhood_nodes\": context_nodes,\n",
    "        \"context_text\": \"\\n\".join(context_texts),\n",
    "    }\n",
    "    \n",
    "graph_question = \"What critical issues is Acme Corp facing and how might it affect their subscriptions?\"\n",
    "graph_result = retrieve_graph_neighborhood(graph_question, top_n_nodes=3, max_hops=2)\n",
    "graph_result[\"context_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a500ec",
   "metadata": {},
   "source": [
    "### 3.3. GraphRAG Answer Stub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aabcf2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: What critical issues is Acme Corp facing and how might it affect their subscriptions?\n",
      "\n",
      "GRAPH SEED NODES:\n",
      "['ticket:1004', 'order:102', 'customer:3']\n",
      "\n",
      "GRAPH CONTEXT (neighbors up to 2 hops):\n",
      "[customer:1] Customer Acme Corp (segment: Enterprise, region: NA). Node: customer:1.\n",
      "[customer:3] Customer Initech (segment: SMB, region: NA). Node: customer:3.\n",
      "[order:101] Order 101 for customer 1. Product: Observability Suite, amount: 250000, status: Active. Node: order:101.\n",
      "[order:102] Order 102 for customer 1. Product: Incident Automation, amount: 90000, status: Churned. Node: order:102.\n",
      "[order:104] Order 104 for customer 3. Product: Log Analytics, amount: 15000, status: Trial. Node: order:104.\n",
      "[ticket:1001] Ticket 1001 for customer 1. Severity: P1, topic: Frequent outages, status: Open. Node: ticket:1001.\n",
      "[ticket:1002] Ticket 1002 for customer 1. Severity: P2, topic: Slow dashboards, status: Closed. Node: ticket:1002.\n",
      "[ticket:1004] Ticket 1004 for customer 3. Severity: P1, topic: Agent CPU usage, status: Closed. Node: ticket:1004.\n",
      "\n",
      "LLM_ANSWER (pseudo): Based on this graph neighborhood, here is how I would explain the situation...\n"
     ]
    }
   ],
   "source": [
    "def answer_with_graph_rag(question: str, top_n_nodes: int = 3, max_hops: int = 2) -> str:\n",
    "    result = retrieve_graph_neighborhood(question, top_n_nodes=top_n_nodes, max_hops=max_hops)\n",
    "    context = result[\"context_text\"]\n",
    "\n",
    "    # In production: call LLM with this context\n",
    "    answer = (\n",
    "        f\"QUESTION: {question}\\n\\n\"\n",
    "        \"GRAPH SEED NODES:\\n\"\n",
    "        f\"{result['seed_nodes']}\\n\\n\"\n",
    "        f\"GRAPH CONTEXT (neighbors up to {max_hops} hops):\\n{context}\\n\\n\"\n",
    "        \"LLM_ANSWER (pseudo): Based on this graph neighborhood, here is how I would explain the situation...\"\n",
    "    )\n",
    "\n",
    "    return answer\n",
    "\n",
    "print(answer_with_graph_rag(graph_question, top_n_nodes=3, max_hops=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbfd5c2",
   "metadata": {},
   "source": [
    "## 4. Comparing Classic Relational RAG vs GraphRAG\n",
    "- In a real system with millions of rows:\n",
    "    - Classic RAG over relational summaries:\n",
    "        - Works well for questions about individual entities or simple aggregates.\n",
    "        - Retrieval scans a large vector index (ANN makes this efficient, but still global).\n",
    "\n",
    "- GraphRAG:\n",
    "    - Focuses on entities and their relationships.\n",
    "    - Retrieval happens in a smaller subgraph relevant to the question.\n",
    "\n",
    "- Especially useful for:\n",
    "    - Root cause analysis across services\n",
    "    - Churn explanations involving multiple signals\n",
    "    - Impact analysis (“if this service fails, who is affected?”)\n",
    "\n",
    "Below is a simple simulation to illustrate the difference in search space size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ddff937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Retrieval Search Space Comparison (Conceptual) ===\n",
      "Total customers in DB (global index): 10,000,000\n",
      "Approx. nodes examined in a GraphRAG neighborhood: 500\n",
      "GraphRAG search space is ~20,000x smaller for reasoning over this subgraph.\n"
     ]
    }
   ],
   "source": [
    "def compare_retrieval_scale(\n",
    "    total_customers: int = 10_000_000,\n",
    "    avg_neighbors_per_seed: int = 50,\n",
    "    nodes_in_neighborhood: int = 500,\n",
    "):\n",
    "    \"\"\"\n",
    "    Very rough conceptual comparison.\n",
    "    \"\"\"\n",
    "    relational_search_space = total_customers # imagine a global index over customers\n",
    "\n",
    "    # GraphRAG: we only look at a local neighborhood\n",
    "    graph_search_space = nodes_in_neighborhood\n",
    "\n",
    "    print(\"=== Retrieval Search Space Comparison (Conceptual) ===\")\n",
    "    print(f\"Total customers in DB (global index): {relational_search_space:,}\")\n",
    "    print(f\"Approx. nodes examined in a GraphRAG neighborhood: {graph_search_space:,}\")\n",
    "    print(\n",
    "        f\"GraphRAG search space is ~{relational_search_space / graph_search_space:,.0f}x smaller \"\n",
    "        \"for reasoning over this subgraph.\"\n",
    "    )\n",
    "    \n",
    "compare_retrieval_scale()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f53de9",
   "metadata": {},
   "source": [
    "- In reality, you'd have:\n",
    "    - Multiple entity types (customers, services, teams, tickets, incidents, releases, etc.)\n",
    "    - Weighted / typed edges (e.g., ownership, causality, dependency strength)\n",
    "    - More powerful graph queries (Cypher, Gremlin, GQL)\n",
    "    - A dedicated GraphRAG engine that:\n",
    "        - Uses the graph to pick relevant nodes\n",
    "        - Enriches them with text\n",
    "        - Feeds them into an LLM for reasoning\n",
    "\n",
    "- But the core idea remains:\n",
    "    - Relational RAG focuses on rows; GraphRAG focuses on entities and relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef12a79e",
   "metadata": {},
   "source": [
    "## 5. Hybrid Agent: Routing Between Relational RAG and GraphRAG\n",
    "\n",
    "- Finally, we can simulate a simple routing strategy:\n",
    "    - If the question is about one customer and \"churn\" → use GraphRAG\n",
    "    - If the question is about overall statistics → use Relational RAG\n",
    "\n",
    "In production, an LLM classifier (or agent) would make this decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46db207e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: Why is Acme Corp at risk of churn?\n",
      "\n",
      "GRAPH SEED NODES:\n",
      "['customer:2', 'order:103', 'customer:3']\n",
      "\n",
      "GRAPH CONTEXT (neighbors up to 2 hops):\n",
      "[customer:2] Customer Globex Inc (segment: Mid-Market, region: EU). Node: customer:2.\n",
      "[customer:3] Customer Initech (segment: SMB, region: NA). Node: customer:3.\n",
      "[order:103] Order 103 for customer 2. Product: Observability Suite, amount: 60000, status: Active. Node: order:103.\n",
      "[order:104] Order 104 for customer 3. Product: Log Analytics, amount: 15000, status: Trial. Node: order:104.\n",
      "[ticket:1003] Ticket 1003 for customer 2. Severity: P3, topic: Billing questions, status: Open. Node: ticket:1003.\n",
      "[ticket:1004] Ticket 1004 for customer 3. Severity: P1, topic: Agent CPU usage, status: Closed. Node: ticket:1004.\n",
      "\n",
      "LLM_ANSWER (pseudo): Based on this graph neighborhood, here is how I would explain the situation...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "QUESTION: Give me a general summary of our key customers.\n",
      "\n",
      "CONTEXT (top 3 customers):\n",
      "[Customer Acme Corp]\n",
      "Customer Acme Corp (segment: Enterprise, region: NA). Total revenue: 340000. Products: Incident Automation, Observability Suite. Churned products: Churned. Open P1 tickets: 1. Open tickets: 1. Recent ticket topics: Frequent outages, Slow dashboards.\n",
      "\n",
      "[Customer Globex Inc]\n",
      "Customer Globex Inc (segment: Mid-Market, region: EU). Total revenue: 60000. Products: Observability Suite. Churned products: None. Open P1 tickets: 0. Open tickets: 1. Recent ticket topics: Billing questions.\n",
      "\n",
      "[Customer Initech]\n",
      "Customer Initech (segment: SMB, region: NA). Total revenue: 15000. Products: Log Analytics. Churned products: None. Open P1 tickets: 1. Open tickets: 0. Recent ticket topics: Agent CPU usage.\n",
      "\n",
      "LLM_ANSWER (pseudo): Based on the context above, here is how I would explain the situation...\n"
     ]
    }
   ],
   "source": [
    "def route_question(question: str) -> str:\n",
    "    q_lower = question.lower()\n",
    "    if \"why\" in q_lower and (\"churn\" in q_lower or \"root cause\" in q_lower or \"impact\" in q_lower):\n",
    "        return \"graph_rag\"\n",
    "    else:\n",
    "        return \"relational_rag\"\n",
    "\n",
    "def agentic_answer(question: str) -> str:\n",
    "    route = route_question(question)\n",
    "    if route == \"graph_rag\":\n",
    "        return answer_with_graph_rag(question, top_n_nodes=3, max_hops=2)\n",
    "    else:\n",
    "        return answer_with_relational_rag(question, top_k=3)\n",
    "\n",
    "print(agentic_answer(\"Why is Acme Corp at risk of churn?\"))\n",
    "print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "print(agentic_answer(\"Give me a general summary of our key customers.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab7e632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
